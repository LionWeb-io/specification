= Correctness levels

LionWeb provides a notion for correctness of serialization chunks in terms of multiple _levels_.
Each level groups a set of kinds of incorrectness, and whether and how occurrences of these kinds of issues can be meaningfully recovered from.
Additionally, we explain how issues should be reported.
This approach provides a degree of resilience: issues arising in one level don't necessarily prohibit determining whether a serialization chunk exhibits incorrectness on another level, provided an issue can be meaningfully recovered from.

The first three levels pertain purely to the JSON that's supposed to be a serialization chunk, and are language(s)-agnostic — essentially, this is about whether the JSON is _well-formed_ as a serialization chunk in JSON format.
The remaining two levels require language-awareness, but could still take place entirely within the serialization chunk, although for the final, fifth level —constraints— this is usually cumbersome and better performed on a programmatic representation of the model.

We admit some flexibility on the first three, JSON-centric levels.
That is because the behavior and adaptability of JSON parsers differ from implementation to implementation.
E.g., some parsers might simply ignore/skip over trailing commas, or have the last of key-value pairs with duplicate keys "`win`".
We simply can't (and don't want to demand) that a LionWeb implementation always produces the exact same issues, especially if they are —i.e., have severity:— auto-recoverable.

Serialization chunks are by definition allowed to be incomplete.
It's not important whether references resolve _within_ the serialization chunk: an unresolvable reference doesn't affect interoperability/interchangeability.
For this reason, we unresolvable references are regarded as an incorrectness purely _within_ the serialization chunk, but one with _stubbable_ severity.

We give an overview of the various levels, and what each pertains to.
At first, we do this without specifying the corresponding kinds of issues that may arise in that level.
The list is roughly in order from low-level and language-agnostic, to language(s)-specific.

[horizontal]

JSON::
Pertains to the text that's (supposed to be) the JSON serialization chunk.
This is the lowest syntactic level.

Structural::
Pertains to the syntactic structure of the (succesfully) parsed JSON text.

Hierarchical::
Pertains to relational constraints within the parsed JSON text.

Meta-structural::
This means that the serialization chunk conforms to the language(s) it declares to be an instance of.

Constraints::
This pertains to a semantic, language(s)-specific notion of correctness.

[NOTE]
====
For all levels except for the constraints, it's possible to identify a fully-specified set of kinds of issues that may arise at each of them, based purely on the LionWeb specification for the JSON serialization format.
To keep this document readable, we first discuss all the levels, and describe that set of kinds of issues elsewhere.
In particular, that description will be derived from the implementation of the `@lionweb/validation` package.
====

We elaborate on these levels now, below.

== JSON (low-level syntactic)

This boils down to whether the text (or byte stream) that's supposed to be a serialization chunk, is a valid JSON document.
Issues arising on this level typically have severity fatal, or auto-recoverable by means of ignoring the problem.
However, ignoring the problem might also hide information by skipping over unparseable content that could be made parseable through intervention.
As already mentioned: whether it's possible to even generate an issue depends completely on the JSON parser used.

== Structural syntactic

In essence, this level is equivalent to conforming to a generic, language-agnostic JSON Schema —or some other formalism to describe the syntactic structure of the JSON— for the serialization format.
The expressive power of JSON Schema is relatively weak, so we also need the hierarchical level, but at least there's good support for JSON Schema across platforms/programming languages that allows this to be implemented fairly quickly.

== Hierarchical

Issues with the JSON that can't be caught at the structural syntactic level should be caught at this level.
Examples of hierarchical issues are:

* Multiple nodes with the same ID occur.
* A node that declares a certain parent node must be contained as a child of that parent node — provided that parent node is present in the serialization chunk; if it's not, then we can't check that constraint.

== Meta-structural

This level requires knowledge of the languages that a serialization chunk declares to conform to.
Examples of meta-structural issues are:

* Meta-pointers can't be resolved (within the languages that the serialization chunk declares to conform to).
* A node must declare values for the features of the classifier it declares.

== Referential

The single issue arising at this level (with stubabble severity) is that the target of a `Reference` feature can't be found, either in the serialization chunk itself or in nodes provided from elsewhere.

== Constraints

We choose to pragmatically treat the constraints level as a special correctness level, as constraint violations don't affect interoperability/interchangeability directly.

A violation of a constraint would typically lead to a direct failure in the model's semantics — i.e.: its execution through interpretation, or generating code and running that —, or to the result of the semantics not making sense in the (context of the) domain, or both.
It's up to the language(s) designers to make that distinction (whenever it exists) clear to the language's users.

We give an example of a language-specific constraint.
Consider a language with core concepts _tables_, _columns_ within those, and SQL-like _queries_.
These queries _reference_ columns within tables, e.g., in the form: `<table>.<column>`.
A constraint for any reference would be: "`in a reference to a column of a referenced table, the column referenced must be a column of the referenced table`".

Another example would be that names should appear uniquely within bounded contexts.

In our experience (and independent of/orthogonal to the two sublevels), a significant part of constraints is "`type-informed`" which means that _type computation/derivation_ is typically an intrinsic part of the constraints aspect of any language.

This level is probably most conveniently phrased in terms of a programmatic representation, but for every programmatic representation there's an equivalent formulation purely in terms of the serialization format.
This works just as well, and maybe even better, because semantics can be more generically "`patched`" w.r.t. non-resolving references.
However, the constraints are not necessarily specified in a form that's interpretable in terms of a serialization chunk, and agnostic to any particular programmatic representation.
That might be enough of an obstacle to compute constraint violations only on the programmatic level, and disregarding it completely on the level of serialization chunks.

[NOTE]
====
LionWeb uses explicit, ID-based references, which means that scoping is not needed to resolve references.
Nevertheless, scoping probably still plays some role in any language.
The constraint stated above can be interpreted as a scoping rule, and the language's UI should take it into account when providing content assist to the language's users.
====

