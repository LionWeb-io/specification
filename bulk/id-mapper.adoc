= ID Mapping API Idea

*How to read:* First read the use cases _without the implementation part_.
Then read changes, and have a look at the examples.
Finally, investigate the implementation part of use cases.


== Use cases
NOTE: If the repository accepted "made-up" node ids (i.e. Jos' proposal), we can omit the _Bulk.ids_ calls below.

Update::
We parse `StringUtils.java` and create an AST.
All nodes that have a recognizable identity (i.e. can be referred to) have a `fqn` property.
We work with the AST, and refer to some of its "identifiable" nodes from other parts of the model.
+
Some time later, we re-parse `StringUtils.java` because it changed a bit.
We update properties or descendants of changed "identifiable" nodes, add and remove some "identifiable" nodes.
+
--
.Implementation
1. _Bulk.ids_ to get a list of unused ids.
2. _Bulk.store_ with `StringUtils` AST.
3. _Bulk.ids_ to get a list of unused ids.
4. _Bulk.retrieve_ with `idProperty` set, send fqn of `StringUtil` and omit `depth` (i.e. unlimited).
5. For each "identifiable" node in AST, look up node with same fqn in response.
6. _Bulk.store_ with node ids from lookup for changed nodes, node ids from _Bulk.ids_ call for new nodes.

#ISSUE: Step 5 very cumbersome.#
--

Direct bind::
We parse `Main.java`, find a reference to `StringUtils`, and parse `StringUtils.java` in the same parser run.
We build cross-references between `Main` AST and `StringUtils` AST.
+
--
.Implementation
1. _Bulk.ids_ to get a list of unused ids.
2. _Bulk.store_ with `StringUtils`  and `Main` AST, reference to `StringUtils` with `[id=<id of StringUtils>>,resolveInfo=<fqn of StringUtils>]`.
--

Parse then refer::
We parse `StringUtils.java`, create an AST, and store it in the repository.
+
Some time later, we parse `Main.java`, and build an AST.
It contains a reference to `StringUtils`, which we resolve _without_ re-parsing `StringUtils.java`.
+
--
.Implementation
1. _Bulk.ids_ to get a list of unused ids.
2. _Bulk.store_ with `StringUtils` AST.
3. _Bulk.ids_ to get a list of unused ids.
4. _Bulk.store_ with `Main` AST, reference to `StringUtils` with `[id=null,resolveInfo=<fqn of StringUtils>]`..
5. Invoke _Resolver_ processor.
--

Refer then parse::
We parse `Main.java`, and find an unresolvable reference to `StringUtils`.
+
Some time later, we parse `StringUtils.java`.
Then we run reference resolution on our model, and establish the reference from `Main` to `StringUtils`.
+
--
.Implementation
1. _Bulk.ids_ to get a list of unused ids.
2. _Bulk.store_ with `Main` AST, reference to `StringUtils` with `[id=null,resolveInfo=<fqn of StringUtils>]`.
3. _Bulk.ids_ to get a list of unused ids.
4. _Bulk.store_ with `StringUtils` AST.
5. Invoke _Resolver_ processor.
--

Search FQN::
We somehow got our hands on a fqn of an "identifiable" node.
We want to know if there is a fitting entry in the repository.
+
--
.Implementation
_Bulk.retrieve_ with `idProperty` set and send fqns instead of node ids.
--

List FQNs::
We stored all our "identifiable" nodes in one partition in the repository.
We want to list all of their fqns.
+
--
.Implementation
_Bulk.retrieve_ with partition's node id.
Read `fqn` property of all children of partition.
--

Stable element URIs::
We parsed `StringUtils.java` in repo `R1`, and link to "identifiable" nodes from an external wiki.
The link might be https://example.com/nodes/org.apache.commons.lang3.StringUtils.toFirstUpper.
We change the repo implementation to `R2` of another brand.
The link should be stable.
+
See <<stable-uri-discussion>>.

== Changes

1. Define an annotation `Id` on `Property` on M2 level.
We can retrieve nodes via _Bulk.retrieve_ by the value of that property.
We might have a boolean flag `unique` on that annotation, to signal that the value MUST be globally unique.
+
A supporting repository SHOULD create an index for such properties to access them efficiently.
If we supported the `unique` flag, the repository can configure the index accordingly.

2. Define an annotation `ResolveBy` on `Reference` on M2 level.
The annotation has one reference `target` that points to a `Property` with `Id` annotation.
It indicates to a _resolver_ processor to use the value of the `target` Property for resolution.

3. Add another parameter `idProperty` to _Bulk.retrieve_ that contains the key of a Property annotated with `Id`.
Then the `nodes` parameter does not contain node ids, but the value of that property.
+
The result would be the same as always, so we get the node ids and the property with `Id` annotation as usual.


== Example Language
----
Concept Function                   [key=func]
  @Id(unique=true)
  property fqn: String             [key=fully]
  property name: String            [key=naaaam]
  containment body: CodeBlock[1]   [key=myflesh]

Concept FunctionCall extends Expression  [key=fnCall]
  @ResolveBy(target=-> fqn)
  reference function: Function           [key=fnTarget]
----

== Example instance creation
.Instance 1
----
Function [id=123] {
  fqn = "org.apache.commons.lang3.StringUtils.toFirstUpper()"
  name = "toFirstUpper"
  body = StatementList [id=124] { ... }
}
----

.Instance 2
----
Function [id=220] {
  fqn = "com.example.Main.main()"
  name = "main"
  body = StatementList [id=222] {
    FunctionCall [id=432] {
      function = -> [id=null, resolveInfo="org.apache.commons.lang3.StringUtils.toFirstUpper()"]
    }
  }
}
----

== Example Bulk retrieve
.With regular ids
----
GET /bulk/retrieve?depthLimit=5

[
  "123",
  "220"
]
----

.With mapped ids
----
GET /bulk/retrive?depthLimit=5&idProperty=fully

[
  "org.apache.commons.lang3.StringUtils.toFirstUpper()",
  "com.example.Main.main()"
]
----

== Comparison to Bulk API

partitions::
No change: Request doesn't involve any ids, response as usual.

ids::
No change: We never ask for unused mapped ids.

store::
No change in syntax, might have in semantics:
If we allowed `@Id(unique=true)`, the repository MUST reject nodes with the same node id, but different `@Id` property value.

retrieve::
Add another parameter `idProperty` as described above.
Compatible with all other capabilities.

[[stable-uri-discussion]]
== Stable URI discussion
How would that work in existing systems?
This is important because we want to be compatible with lots of systems.

We'll look at node URIs of "identifiable elements" in these variants for each system:

1. Copy existing repo `R1` from system _X_ to new instance `R2` of system _X_.
2. Copy existing repo `R1` from system _Y_ to new instance `R2` of systems _X_.
_Y_ might use arbitrary LionWeb-compatible node ids.
3. Re-create existing repo `R1` in system _X_ from identical sources in same order.
4. Re-create existing repo `R1` in system _X_ from identical sources in different order (e.g. because the file system listed the files in different order, or we use a hashmap somewhere in the processing chain).
5. Re-create existing repo `R1` in system _X_ from slightly changed sources in same order.

=== MPS
MPS uses user-given names to identify projects, random UUIDs to identify models, and random longs to identify nodes (although it supports _foreign node ids_ consisting of arbitrary strings).

NOTE: The _local_ node URLs of MPS (http://127.0.0.1:63320/node?ref=r%3A5d0bf864-ad8e-487e-9a12-36abdfcf2e40%28io.lionweb.PROPS.structure%29%2F7815373512446180605) only work because we're all working on the _same_ repository (synced via git).

.Copy existing repo `R1` from system _X_ to new instance `R2` of system _X_
Node URIs unstable because of randomly chosen model and node id.

.Copy existing repo `R1` from system _Y_ to new instance `R2` of systems _X_
Node URIs unstable because of randomly chosen model and node id.

.Re-create existing repo `R1` in system _X_ from identical sources in same order
Node URIs unstable because of randomly chosen model and node id.

.Re-create existing repo `R1` in system _X_ from identical sources in different order
Node URIs unstable because of randomly chosen model and node id.

.Re-create existing repo `R1` in system _X_ from slightly changed sources in same order
Node URIs unstable because of randomly chosen model and node id.

=== Ecore
We assume Xtext implementation: name-based URIs for "identifiable" nodes, positional URIs relative to the closest "identifiable" ancestor for the rest.

Example:

[source, java]
----
package org.apache.commons.lang3;

class StringUtils {
    // WRONG implementation!
    String toFirstUpper(String input) {
        char firstChar = input.charAt(0);
        if (firstChar > 'z') {            // <1>
            // ...
        }
    }
}
----
<1> URI of `firstChar` would be http://example/com/nodes/org.apache.commons.lang3.StringUtils.toFirstUpper/statements/1/condition/left

.Copy existing repo `R1` from system _X_ to new instance `R2` of system _X_
Stable node URIs, as long as they are contained in some "identifiable" node.

.Copy existing repo `R1` from system _Y_ to new instance `R2` of systems _X_
Node URI could be stable if globally unique (i.e. no nested scopes).

.Re-create existing repo `R1` in system _X_ from identical sources in same order
Stable node URIs, as long as they are contained in some "identifiable" node.

.Re-create existing repo `R1` in system _X_ from identical sources in different order
Stable node URIs, as long as they are contained in some "identifiable" node.
Non-"identifiable" nodes would change their URI (as they are positional).

.Re-create existing repo `R1` in system _X_ from slightly changed sources in same order
Stable node URIs, as long as they are contained in some "identifiable" node.
Non-"identifiable" nodes would change their URI (as they are positional).

=== Enterprise Architect
EA identifies nodes by random UUIDs.

.Copy existing repo `R1` from system _X_ to new instance `R2` of system _X_
Node URIs unstable because of randomly chosen node id.

.Copy existing repo `R1` from system _Y_ to new instance `R2` of systems _X_
Node URIs unstable because of randomly chosen node id.

.Re-create existing repo `R1` in system _X_ from identical sources in same order
Node URIs unstable because of randomly chosen node id.

.Re-create existing repo `R1` in system _X_ from identical sources in different order
Node URIs unstable because of randomly chosen node id.

.Re-create existing repo `R1` in system _X_ from slightly changed sources in same order
Node URIs unstable because of randomly chosen node id.

=== Relational Database
We assume naive scheme: tables with numeric `id` column with `AUTO_INCREMENT` feature.

.Copy existing repo `R1` from system _X_ to new instance `R2` of system _X_
Depends highly on the implementation: If we copied table-by-table and never deleted any row, the re-created entries would probably end up with the same id and thus URI.
Probably unstable if we didn't meet any of the conditions above.

.Copy existing repo `R1` from system _Y_ to new instance `R2` of systems _X_
Node URIs unstable because we must map external arbitrary node ids to internal integers.

.Re-create existing repo `R1` in system _X_ from identical sources in same order
Stable node URIs (assuming no deletions ever).

.Re-create existing repo `R1` in system _X_ from identical sources in different order
Node URIs unstable because they depend on processing order.

.Re-create existing repo `R1` in system _X_ from slightly changed sources in same order
Depends on the change: If we only changed names or other properties, node URIs would be stable (as they are processed in the same order).
Any other change (add/remove nodes, change order, change nesting) would lead to unstable URIs.

=== Modelix
Modelix uses globally unique longs as node ids.

.Copy existing repo `R1` from system _X_ to new instance `R2` of system _X_
Stable node URIs only if we never deleted any node in `R1`.

.Copy existing repo `R1` from system _Y_ to new instance `R2` of systems _X_
Node URIs unstable because we must map external arbitrary node ids to internal integers.

.Re-create existing repo `R1` in system _X_ from identical sources in same order
Stable node URIs (assuming no deletions ever).

.Re-create existing repo `R1` in system _X_ from identical sources in different order
Node URIs unstable because they depend on processing order.

.Re-create existing repo `R1` in system _X_ from slightly changed sources in same order
Depends on the change: If we only changed names or other properties, node URIs would be stable (as they are processed in the same order).
Any other change (add/remove nodes, change order, change nesting) would lead to unstable URIs.

=== Rascal
Rascal uses _SourceLocations_ into immutable sources to identify elements.
Example (made-up from my limited understanding of Rascal): `a/b/c.java#line50column20`

.Copy existing repo `R1` from system _X_ to new instance `R2` of system _X_
Stable node URIs.

.Copy existing repo `R1` from system _Y_ to new instance `R2` of systems _X_
???

.Re-create existing repo `R1` in system _X_ from identical sources in same order
Stable node URIs.

.Re-create existing repo `R1` in system _X_ from identical sources in different order
Stable node URIs.

.Re-create existing repo `R1` in system _X_ from slightly changed sources in same order
Node URIs unstable because source location would move

=== MetaEdit+
???

.Copy existing repo `R1` from system _X_ to new instance `R2` of system _X_

.Copy existing repo `R1` from system _Y_ to new instance `R2` of systems _X_

.Re-create existing repo `R1` in system _X_ from identical sources in same order

.Re-create existing repo `R1` in system _X_ from identical sources in different order

.Re-create existing repo `R1` in system _X_ from slightly changed sources in same order

=== Neo4J
???

As far as I understand from link:https://neo4j.com/docs/ogm-manual/current/reference/#reference:annotating-entities:entity-identifier[Neo4J Documentation],
by default it uses long integers -- but it supports user-defined ids.

.Copy existing repo `R1` from system _X_ to new instance `R2` of system _X_

.Copy existing repo `R1` from system _Y_ to new instance `R2` of systems _X_

.Re-create existing repo `R1` in system _X_ from identical sources in same order

.Re-create existing repo `R1` in system _X_ from identical sources in different order

.Re-create existing repo `R1` in system _X_ from slightly changed sources in same order
